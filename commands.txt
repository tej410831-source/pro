python -m vllm.entrypoints.openai.api_server `
    --model Qwen/Qwen2.5-Coder-7B-Instruct `
    --port 8000 `
    --max-model-len 4096 `
    --device auto


curl http://localhost:8000/v1/models


python main.py analyze ./your_project --vllm-url http://localhost:8000/v1



"rope_scaling": {
    "factor": 4.0,
    "original_max_position_embeddings": 32768,
    "type": "yarn"
  }


  python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2.5-Coder-7B-Instruct \
    --port 8000 \
    --max-model-len 32768 \
    --rope-scaling "{\"type\": \"yarn\", \"factor\": 4.0, \"original_max_position_embeddings\": 32768}" \
    --device auto